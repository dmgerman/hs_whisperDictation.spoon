#+title: WhisperDictation Development Guide
#+author: dmg
#+date: 2025
#+language: en

* Architecture

The Spoon follows a modular design with clear separation of concerns:

** Component Overview

*** Logger System
Custom structured logging with support for multiple levels (DEBUG, INFO, WARN, ERROR) and outputs (console and file). Provides unified logging throughout the Spoon.

*** Recording Backend System
Pluggable recording architecture supporting multiple backends:

**** Sox Backend (Simple)
- One-shot recording to single WAV file
- Starts =sox= process on begin, terminates on stop
- Simple but no advanced features

**** Python Stream Backend (Continuous with VAD)
- **Persistent server**: Starts once, stays running between recordings
- **Event-driven**: TCP socket communication (newline-delimited JSON)
- **Silero VAD**: Automatic chunk detection based on silence
- **Real-time**: Chunks transcribed as they're recorded
- **Auto-stop**: Detects microphone off (perfect silence)

**Persistent Server Architecture:**
1. Server starts asynchronously during spoon initialization (~2-3s for VAD model load)
2. Server stays running, waiting for commands
3. Recording sends =start_recording= command → server begins capture
4. Server sends events: =recording_started=, =chunk_ready=, =recording_stopped=
5. Recording sends =stop_recording= command → server saves final chunk, stays alive
6. Server only exits on =shutdown= command or spoon stop

**Benefits:**
- First recording: ~300ms (no model loading)
- Subsequent recordings: Instant (server already warm)
- No startup latency or "first words cut off" issues

*** Transcription Method System (Pluggable Architecture)
Core innovation allowing multiple transcription backends without code duplication. Each method is self-contained with:

**** Method Interface
Each transcription method must implement:

- =config=: Table containing method-specific configuration (paths, models, etc.)
- =validate()=: Returns true if dependencies exist and are accessible
- =transcribe(audioFile, lang, callback)=: Transcribes audio file and calls =callback(success, text_or_error)=

**** Built-in Methods

| Method        | Transport    | Output       | Use Case                                    |
|---------------+--------------+--------------+---------------------------------------------|
| whisperkitcli | CLI process  | stdout       | Apple's optimized, auto-download            |
| whispercli    | CLI process  | .wav.txt     | Local C++ implementation                    |
| whisperserver | HTTP POST    | HTTP response| Fastest for repeated use (model stays loaded)|

*** Language Manager
Simple language selection system:
- =obj.languages=: List of supported language codes
- =obj.langIndex=: Currently selected language index
- =showLanguageChooser()=: Interactive chooser menu

*** Menubar Interface
Provides visual status and interaction:
- Displays current state (idle, recording with elapsed time, transcribing)
- Shows active language code
- Click to toggle recording

** Data Flow

#+begin_src
User hotkey (toggle) → toggleRecord()
  → startRecording() [sox -d file.wav]
  → menubar shows recording + elapsed time
  → User hotkey (toggle) again
  → stopRecording()
  → transcribe(audioFile)
    → Get selected method from obj.transcriptionMethods[obj.transcriptionMethod]
    → method:transcribe(audioFile, lang, callback)
      → (method handles its own async execution)
    → handleTranscriptionResult() callback
      → Save to .txt file
      → Copy to clipboard (or call user callback)
      → Reset menubar to idle
#+end_src

* Extending with Custom Methods

You can add custom transcription methods by adding them to =obj.transcriptionMethods=:

#+begin_src lua
-- Example: Custom transcription method
wd.transcriptionMethods.mymethod = {
  name = "mymethod",
  displayName = "My Custom Transcriber",
  config = {
    cmd = "/path/to/transcriber",
    apiKey = "your-api-key",
    -- Add any method-specific options
  },

  -- Check if the transcriber is available
  validate = function(self)
    return hs.fs.attributes(self.config.cmd) ~= nil
  end,

  -- Transcribe the audio file
  -- Must call callback(success, text_or_error) when done
  transcribe = function(self, audioFile, lang, callback)
    local args = {
      "--audio", audioFile,
      "--language", lang,
      "--api-key", self.config.apiKey,
    }

    local task = hs.task.new(self.config.cmd, function(exitCode, stdOut, stdErr)
      if exitCode ~= 0 then
        callback(false, "Transcriber failed: " .. (stdErr or "unknown error"))
        return
      end

      local text = stdOut or ""
      if text == "" then
        callback(false, "Empty transcription output")
        return
      end

      callback(true, text)
    end, args)

    if task then
      task:start()
    else
      callback(false, "Failed to create task")
    end
  end,
}

-- Select your custom method
wd.transcriptionMethod = "mymethod"
wd:start()
#+end_src

* Contributing

Bug reports and suggestions are welcome. Please open an issue or submit a pull request.
