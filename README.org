#+title: WhisperDictation - Voice to Text for Mac
#+author: dmg
#+date: 2026

Speak and see your words appear as text. Works offline, supports 100+ languages, and puts privacy first.

* âš ï¸ Version 2.0 - Rearchitected

*This version has been completely rearchitected* for better reliability and maintainability:
- New callback-based architecture (simpler, more testable)
- Improved error handling and state management
- 408+ comprehensive tests

*Breaking changes from v1.x:*
- Configuration API changed (see examples below)
- =recordingBackend= â†’ =config.recorder=
- =transcriptionMethod= â†’ =config.transcriber=
- =pythonstream= â†’ =streaming=

If upgrading from v1.x, you'll need to update your configuration.

* What Does It Do?

1. *Press a hotkey* to start recording
2. *Speak* your text
3. *Press the hotkey again* to stop
4. *Get your text* - either pasted automatically or copied to clipboard

That's it!

* Quick Start

** 1. Choose Your Setup

Pick based on what you value most:

*** ðŸ”’ *Private & Offline* (Apple Silicon Macs - Recommended)

#+begin_src lua
-- Add to ~/.hammerspoon/init.lua
local wd = hs.loadSpoon("hs_whisperDictation")

-- Configure
wd.config = {
  recorder = "sox",           -- Simple recording
  transcriber = "whisperkit", -- Apple optimized, local
}

-- Set your hotkey (Ctrl+Cmd+D)
wd:bindHotKeys({
  toggle = {{"ctrl", "cmd"}, "d"}
})

wd:start()
#+end_src

*Install:* =brew install sox whisperkit-cli=

*Pros:* 100% private, offline, Apple Silicon optimized, fast

*Cons:* Requires Mac with M1/M2/M3/M4 chip

*** âš¡ *Pro Setup* (Fastest Transcription)

#+begin_src lua
local wd = hs.loadSpoon("hs_whisperDictation")

wd.config = {
  recorder = "streaming",        -- Smart recording with VAD
  transcriber = "whisperserver", -- Fastest transcription
  whisperserver = {
    port = "8080"
  }
}

wd:bindHotKeys({
  toggle = {{"ctrl", "cmd"}, "d"}
})

wd:start()
#+end_src

*Install:*

#+begin_src bash
# Install whisper.cpp server
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
make server
./models/download-ggml-model.sh large-v3

# Run server (in background)
./server -m models/ggml-large-v3.bin -p 8080 &

# Install streaming recorder
pip install sounddevice scipy torch
#+end_src

*Pros:* Fastest transcription, real-time chunk processing, intelligent silence detection

*Cons:* Significant memory usage (model stays in RAM), more complex setup

** 2. Set Your Language

#+begin_src lua
wd.languages = {"en"}  -- English only
-- Or multiple:
wd.languages = {"en", "ja", "es", "fr"}  -- English, Japanese, Spanish, French
#+end_src

Press *Ctrl+Cmd+L* to switch languages while running.

** 3. Test It

1. Press *Ctrl+Cmd+D* (or your chosen hotkey)
2. See the menubar icon change (ðŸŽ™ï¸ recording indicator)
3. Speak: "Hello world, this is a test"
4. Press *Ctrl+Cmd+D* again
5. Your text appears in the clipboard - paste it anywhere!

* Common Use Cases

** Copy to Clipboard

Default behavior - transcribed text goes to clipboard.

#+begin_src lua
wd:bindHotKeys({
  toggle = {{"ctrl", "cmd"}, "d"}
})
#+end_src

*Usage:* Press hotkey â†’ Speak â†’ Press hotkey â†’ Paste (Cmd+V)

** Auto-Paste (Beta)

Text automatically pastes if you don't type/click during recording.

#+begin_src lua
wd.monitorUserActivity = true

wd:bindHotKeys({
  toggle = {{"ctrl", "cmd"}, "d"},      -- Copy mode
  togglePaste = {{"ctrl", "cmd"}, "p"}  -- Auto-paste mode
})
#+end_src

*Usage:* Press *Ctrl+Cmd+P* â†’ Speak â†’ Press *Ctrl+Cmd+P* â†’ Text auto-pastes!

*When it auto-pastes:*
- âœ… You stayed in the same app
- âœ… You didn't type anything
- âœ… You didn't click the mouse

*When it just copies to clipboard:*
- âš ï¸ You typed something
- âš ï¸ You clicked the mouse
- âš ï¸ You switched to a different app

** Multiple Languages

Switch on the fly:

#+begin_src lua
wd.languages = {"en", "ja", "es"}

wd:bindHotKeys({
  toggle = {{"ctrl", "cmd"}, "d"},
  nextLang = {{"ctrl", "cmd"}, "l"}  -- Switch language
})
#+end_src

*Usage:* Press *Ctrl+Cmd+L*, choose language, then record

* Transcription Methods

| Method        | What it is                       | Speed      | Privacy    | Best for                       |
|---------------+----------------------------------+------------+------------+--------------------------------|
| *whisperkit*    | Apple Neural Engine on your Mac  | âš¡âš¡ Fast  | 100% local | Privacy-conscious Mac users    |
| *whispercli*    | Whisper on CPU/GPU               | âš¡ Slower  | 100% local | Non-Apple Silicon Macs         |
| *whisperserver* | Local HTTP server (model in RAM) | âš¡âš¡ Fast* | 100% local | Heavy users (*after first use) |

** whisperkit (Apple Silicon - Recommended)

| What it is | Uses Apple's Neural Engine on your Mac               |
| Speed      | âš¡âš¡ Fast                                              |
| Privacy    | 100% local, nothing leaves your Mac                  |
| Best for   | Privacy-conscious Mac users with Apple Silicon       |

*Setup:*

#+begin_src bash
brew install whisperkit-cli
#+end_src

#+begin_src lua
wd.config = {
  transcriber = "whisperkit",
}
#+end_src

** whispercli (CPU/GPU)

| What it is | Runs Whisper on your CPU/GPU                         |
| Speed      | âš¡ Slower                                             |
| Privacy    | 100% local                                           |
| Best for   | Non-Apple Silicon Macs                               |

*Setup:*

#+begin_src bash
brew install whisper-cli
# Download model
mkdir -p /usr/local/whisper
cd /usr/local/whisper
wget https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large-v3.bin
#+end_src

#+begin_src lua
wd.config = {
  transcriber = "whispercli",
  whispercli = {
    modelPath = "/usr/local/whisper/ggml-large-v3.bin"
  }
}
#+end_src

** whisperserver (HTTP Server)

| What it is | Local HTTP server (model stays loaded in RAM)       |
| Speed      | âš¡âš¡ Fast after first use                             |
| Privacy    | 100% local                                           |
| Best for   | Heavy users (model stays in RAM between uses)        |

*Setup:*

#+begin_src bash
# Install whisper.cpp server
git clone https://github.com/ggerganov/whisper.cpp
cd whisper.cpp
make server

# Download model
./models/download-ggml-model.sh large-v3

# Run server (in background)
./server -m models/ggml-large-v3.bin -p 8080 &
#+end_src

#+begin_src lua
wd.config = {
  transcriber = "whisperserver",
  whisperserver = {
    host = "127.0.0.1",
    port = "8080"
  }
}
#+end_src

* Recording Backends

| Backend   | What it is                          | When to use                     |
|-----------+-------------------------------------+---------------------------------|
| *sox*       | Records one file per session        | Simple needs, fallback option   |
| *streaming* | Real-time with smart chunking (VAD) | Long dictations, faster results |

*streaming* is in beta-testing. *sox* should be used if you want utmost reliability.

** sox (Simple - Recommended for Beginners)

*What it is:* Records one file per session

*When to use:* Simple needs, fallback option

*Install:* =brew install sox=

#+begin_src lua
wd.config = {
  recorder = "sox",
}
#+end_src

** streaming (Smart - Advanced)

*What it is:* Real-time recording with smart chunking using Silero VAD

*Features:*
- Detects silence and creates chunks automatically
- Transcribes while you're still talking
- Faster overall for long recordings

*When to use:* Long dictations, want faster results

*Note: streaming* is in beta-testing. *sox* should be used if you want utmost reliability.


#+begin_src bash
pip install sounddevice scipy torch
#+end_src

#+begin_src lua
wd.config = {
  recorder = "streaming",
  streaming = {
    silenceThreshold = 2.0,   -- Seconds of silence before chunk split
    minChunkDuration = 3.0,   -- Minimum chunk length
    maxChunkDuration = 600.0, -- Maximum chunk length
  }
}
#+end_src

* Configuration Reference

** Basic Settings

#+begin_src lua
-- Languages
wd.languages = {"en", "ja"}  -- Available languages
wd.currentLang = "en"         -- Default language

-- Directories
wd.tempDir = "/tmp/whisper_dict"  -- Where audio files are saved

-- Timeouts
wd.timeoutSeconds = 1800  -- Auto-stop after 30 minutes (nil = no limit)

-- UI
wd.showRecordingIndicator = true  -- Show red dot while recording
#+end_src

** Transcriber Configuration

#+begin_src lua
wd.config = {
  transcriber = "whisperkit",  -- or "whispercli" or "whisperserver"

  -- WhisperKit settings
  whisperkit = {
    cmd = "/opt/homebrew/bin/whisperkit-cli",
    model = "large-v3",
  },

  -- Whisper CLI settings
  whispercli = {
    executable = "/opt/homebrew/bin/whisper-cli",
    modelPath = "/usr/local/whisper/ggml-large-v3.bin",
  },

  -- Whisper Server settings
  whisperserver = {
    host = "127.0.0.1",
    port = "8080",
    curlCmd = "/usr/bin/curl",
  },
}
#+end_src

** Recorder Configuration

#+begin_src lua
wd.config = {
  recorder = "streaming",  -- or "sox"

  -- Sox settings
  sox = {
    soxCmd = "/opt/homebrew/bin/sox",
    audioInputDevice = nil,  -- nil = default device
    tempDir = nil,           -- nil = use wd.tempDir
  },

  -- Streaming settings
  streaming = {
    pythonPath = os.getenv("HOME") .. "/.config/dmg/python3.12/bin/python3",
    tcpPort = 12341,
    audioInputDevice = nil,  -- nil = default device, or "BlackHole 2ch" for tests
    silenceThreshold = 2.0,  -- Seconds of silence to trigger chunk boundary
    minChunkDuration = 3.0,  -- Minimum chunk duration (seconds)
    maxChunkDuration = 600.0, -- Maximum chunk duration (seconds)
    tempDir = nil,           -- nil = use wd.tempDir
  },
}
#+end_src

** Auto-Paste Settings

#+begin_src lua
wd.monitorUserActivity = true  -- Enable activity monitoring
wd.autoPasteDelay = 0.1         -- Delay before pasting (seconds)
wd.pasteWithEmacsYank = false   -- Use Ctrl-Y for Emacs (if true)
#+end_src

* Troubleshooting

** "No audio recorded"

*Fix:*
1. Check microphone permissions: System Settings â†’ Privacy & Security â†’ Microphone â†’ Enable Hammerspoon
2. Check microphone selection: System Settings â†’ Sound â†’ Input â†’ Choose your mic
3. Test recording: =sox -d test.wav= (speak for 5 seconds, then Ctrl+C), then =afplay test.wav=

** "Empty transcription"

*Fix:*
1. Verify audio file: =ls -lh /tmp/whisper_dict/*.wav= (should be >100KB)
2. Play recording: =afplay /tmp/whisper_dict/en-*.wav | tail -1=
3. If silent, check microphone in System Settings

** "Streaming server won't start"

*Fix:*

#+begin_src bash
# Check if port is in use
lsof -i :12341

# Kill zombie process if needed
lsof -ti:12341 | xargs kill -9

# Check Python dependencies
pip list | grep -E "sounddevice|torch|scipy"
#+end_src

** "Whisper command not found"

*Fix:*

#+begin_src bash
# For WhisperKit
brew install whisperkit-cli

# For Whisper CLI
brew install whisper-cli

# For sox
brew install sox
#+end_src

** Check what's happening

#+begin_src lua
-- In Hammerspoon console (Cmd+Opt+Ctrl+C)

-- Check current status
print(hs.inspect(wd:getStatus()))

-- List recent recordings
print(hs.execute("ls -lht /tmp/whisper_dict/*.wav | head -5"))

-- Play most recent
latest = hs.execute("ls -t /tmp/whisper_dict/*.wav | head -1"):gsub("\n", "")
hs.execute("afplay " .. latest)
#+end_src

* Advanced: Custom Callback

Instead of clipboard, do whatever you want with the text:

#+begin_src lua
wd:toggleTranscribe(function(text)
  -- Your custom code here
  print("You said: " .. text)

  -- Examples:
  -- Send to app
  hs.urlevent.openURL("myapp://text?content=" .. hs.http.encodeForQuery(text))

  -- Save to file
  local f = io.open("/tmp/dictation.txt", "a")
  f:write(text .. "\n")
  f:close()

  -- Post to webhook
  hs.http.doRequest("https://myserver.com/api", "POST", text)
end)
#+end_src

* Recommended Configurations

** Best for Beginners (Apple Silicon)

#+begin_src lua
wd.config = {
  recorder = "sox",
  transcriber = "whisperkit",
}
#+end_src

** Best for Privacy (Apple Silicon)

#+begin_src lua
wd.config = {
  recorder = "sox",
  transcriber = "whisperkit",
}
#+end_src

** Best for Speed & Long Recordings (Apple Silicon)

#+begin_src lua
wd.config = {
  recorder = "streaming",
  transcriber = "whisperkit",
}
#+end_src

** Best for Non-Apple Silicon Macs

#+begin_src lua
wd.config = {
  recorder = "sox",
  transcriber = "whispercli",
  whispercli = {
    modelPath = "/usr/local/whisper/ggml-large-v3.bin"
  }
}
#+end_src

** Best for Heavy Users (Local, Fast)

#+begin_src lua
wd.config = {
  recorder = "streaming",
  transcriber = "whisperserver",
  whisperserver = {
    port = "8080"
  }
}
#+end_src

** My own

- I keep both the recorder and transcriber in memory (after first use).

#+begin_src lua   :exports both
  dmg_all_keys = {"cmd", "alt", "ctrl"}

  local wd = hs.loadSpoon("hs_whisperDictation")
  wd.languages = {"en", "ja", "es"}
  wd.monitorUserActivity = true
  wd.pasteWithEmacsYank = true

  -- New Architecture (v2) configuration
  wd.config.recorder = 'streaming'  -- Use StreamingRecorder with Python server
  wd.config.transcriber = 'whisperserver'  -- Use WhisperServer transcriber

  -- Configure StreamingRecorder
  wd.config.streaming = {
    pythonPath = os.getenv("HOME") .. "/.config/dmg/python3.12/bin/python3",
    audioInputDevice = nil,  -- nil = default device
    silenceThreshold = 3.0,  -- 3 seconds of silence to trigger chunk
    minChunkDuration = 5.0,  -- 5 seconds minimum before chunking
    maxChunkDuration = 600.0,  -- 10 minutes maximum
    perfectSilenceDuration = 0,  -- 0 = disabled (don't stop on silence at startup)
    tcpPort = 12341,
  }

  -- Configure WhisperServer transcriber
  wd.config.whisperserver = {
    executable = os.getenv("HOME") .. "/.emacs.d/modules/whisper-cli/build/bin/whisper-server",
    modelPath = "/usr/local/whisper/ggml-model.bin",  -- Update this path to your actual model
    host = "127.0.0.1",
    port = 8080,
    startupTimeout = 10,
  }

  wd:bindHotKeys({
      toggle = {dmg_all_keys, "l"},
      togglePaste = {{}, "F15"},
      nextLang = {dmg_all_keys, ";"},
      retranscribe = {dmg_all_keys, "'"},
  })

  wd:start()

#+end_src

* Privacy & Security

*What stays on your Mac:*
- All configurations
- All recordings (in =/tmp/whisper_dict/=)
- All transcriptions (100% local processing)

*What leaves your Mac:*
- Nothing - no telemetry, no tracking, no cloud services

*To maximize privacy:*
- Use =whisperkit= or =whispercli= transcription
- Use =sox= or =streaming= recording backend
- Audio stays 100% local, always

* License

MIT License - See LICENSE file

* For Developers

- [[file:docs/architecture.md][Architecture Documentation]] - Current v2.0 architecture
- [[file:docs/testing.md][Testing Guide]] - 408+ tests
- [[file:recorders/streaming/whisper_stream.md][Streaming Recorder Documentation]] - Python VAD server
